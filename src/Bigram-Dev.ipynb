{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/iansnyder/Desktop/Projects/Spotify_Proj/Data/input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !\"#$%&'()*+,-./0123456789:;<>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxyz|®ÁÉÍÑÓØÚÜàáãçèéëíñóôöúДНПежилно—’“”垂的直\n",
      "127\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hii there\n",
      "torch.Size([960407]) torch.int64\n",
      "tensor([ 81,  79,  62,  64,  72,  46,  62,  74,  66,   0,  40,  62,  81,  66,\n",
      "          1,  52,  69,  66,   1,  47,  81,  69,  66,  79,   1,  51,  70,  65,\n",
      "         66,   1,   9,  84,  70,  81,  69,   1,  45,  62,  79,  80,  69,  74,\n",
      "         66,  73,  73,  76,   1,   7,   1,  52,  69,  66,   1,  43,  70,  65,\n",
      "          1,  44,  62,  79,  76,  70,  10,   0,  40,  62,  81,  66,   1,  52,\n",
      "         69,  66,   1,  47,  81,  69,  66,  79,   1,  51,  70,  65,  66,   1,\n",
      "          9,  84,  70,  81,  69,   1,  45,  62,  79,  80,  69,  74,  66,  73,\n",
      "         73,  76,   1,   7,   1,  52,  69,  66,   1,  43,  70,  65,   1,  44,\n",
      "         62,  79,  76,  70,  10,   0,  53,  75,  72,  75,  76,  84,  75,   1,\n",
      "         52,  79,  62,  64,  72,   0,  50,  66,  62,  73,  66,  79,   1,  46,\n",
      "          1,  50,  66,  62,  73,  66,  79,   0,  76,  63,  83,  70,  76,  82,\n",
      "         80,   1,   9,  67,  66,  62,  81,  15,   1,  52,  79,  62,  83,  70,\n",
      "         80,   1,  34,  62,  79,  72,  66,  79,  10,   0,  51,  66,  66,   1,\n",
      "         55,  62,  81,   1,  41, 121,  74,   1,  51,  62,  86,  70,  75,   0,\n",
      "         37,  85,  77,  66,  79,  70,  66,  75,  64,  66,   0,  40,  70,  68,\n",
      "         69,  66,  80,  81,   1,  70,  75,   1,  81,  69,  66,   1,  50,  76,\n",
      "         76,  74,   0,  50,  53,  45,  34,  44,  37,   0,  47,  69,   1,  47,\n",
      "         72,  62,  86,   1,   9,  67,  66,  62,  81,  15,   1,  57,  76,  82,\n",
      "         75,  68,   1,  52,  69,  82,  68,   1,   7,   1,  44,  70,  73,   1,\n",
      "         34,  62,  63,  86,  10,   0,  52,  69,  79,  76,  82,  68,  69,   1,\n",
      "         81,  69,  66,   1,  38,  70,  79,  66,   1,  62,  75,  65,   1,  38,\n",
      "         73,  62,  74,  66,  80,   0,  41,  74,  77,  76,  80,  80,  70,  63,\n",
      "         73,  66,   0,  44,  70,  72,  66,   1,  52,  76,  86,   1,  51,  76,\n",
      "         73,  65,  70,  66,  79,  80,   0,  35,  62,  75,   8,  81,   1,  34,\n",
      "         66,   1,  34,  79,  76,  72,  66,  75,   0,  41,  81,   8,  80,   1,\n",
      "         47,  83,  66,  79,   1,  55,  69,  66,  75,   1,  41,  81,   8,  80,\n",
      "          1,  47,  83,  66,  79,   0,  50,  53,  45,  34,  44,  37,   0,  40,\n",
      "         62,  74,  74,  66,  79,   1,  52,  70,  74,  66,   1,   9,  67,  66,\n",
      "         62,  81,  15,   1,  18,  43,   1,  48,  69,  66,  84,  10,   0,  44,\n",
      "         70,  72,  66,   1,  52,  76,  86,   1,  51,  76,  73,  65,  70,  66,\n",
      "         79,  80,   0,  39,  76,  81,  81,  62,   1,  40,  62,  83,  66,   1,\n",
      "         41,  81,   0,  18,  18,  22,   0,  45,  76,  79,  66,   1,  52,  70,\n",
      "         74,  66,   0,  35,  76,  74,  70,  75,  68,   1,  36,  76,  84,  75,\n",
      "          0,  58,  37,  48,  40,  57,  50,   0,  39,  79,  66,  66,  75,   1,\n",
      "         44,  70,  68,  69,  81,  80,   0,  34,  66,  73,  70,  66,  83,  66,\n",
      "         79,   0,  52,  69,  66,   1,  54,  70,  63,  66,   1,   9,  50,  66,\n",
      "         74,  70,  85,  10,   1,  59,  67,  66,  62,  81,  15,   1,  57,  82,\n",
      "         75,  68,   1,  38,  82,  80,  70,  76,  75,  60,   0,  39,  79,  66,\n",
      "         66,  75,   1,  44,  70,  68,  69,  81,  80,   0,  52,  69,  66,   1,\n",
      "         54,  70,  63,  66,   1,   9,  50,  66,  74,  70,  85,  10,   1,  59,\n",
      "         67,  66,  62,  81,  15,   1,  57,  82,  75,  68,   1,  38,  82,  80,\n",
      "         70,  76,  75,  60,   0,  51,  69,  66,   1,  55,  76,  73,  67,   1,\n",
      "          9,  38,  62,  73,  73,  70,  75,  68,   1,  81,  76,   1,  48,  70,\n",
      "         66,  64,  66,  80,  10,   1,  59,  67,  66,  62,  81,  15,   1,  51,\n",
      "         70,  62,  60,   0,  35,  62,  75,  65,  86,   1,  51,  69,  76,  77,\n",
      "          0,  33,  70,  79,  77,  73,  62,  75,  66,  80,   1,   9,  67,  66,\n",
      "         62,  81,  15,   1,  40,  62,  86,  73,  66,  86,   1,  55,  70,  73,\n",
      "         73,  70,  62,  74,  80,   1,  76,  67,   1,  48,  62,  79,  62,  74,\n",
      "         76,  79,  66,  10,   0,   3,  41,   1,  46,  66,  66,  65,   1,  57,\n",
      "         76,  82,  79,   1,  44,  76,  83,  66,   1,   9,  67,  66,  62,  81,\n",
      "         15,   1,  45,  76,  69,  76,  74,  63,  70,  13,   1,  38,  62,  86,\n",
      "         65,  66,  66,   1,   7,   1,  35,  76,  80,  81,  70,  10,   3,   0,\n",
      "         38,  73,  66,  85,  70,  75,   8,   0,  55,  69,  70,  81,  66,   1,\n",
      "         55,  62,  73,  73,  80,   1,   9,  67,  66,  62,  81,  15,   1,  51,\n",
      "         64,  40,  76,  76,  73,  63,  76,  86,   1,  49,   1,   7,   1,  40,\n",
      "         76,  73,  73,  70,  80,  10,   0,   3,  45,  66,  13,   1,  45,  86,\n",
      "         80,  66,  73,  67,   1,   7,   1,  41,   3,   0,  46,  66,  74,  66,\n",
      "         80,  70,  80,   0,  51,  62,  86,   1,  57,  66,  62,  69,   0,  48,\n",
      "         76,  84,  66,  79,  67,  82,  73,   0,  35,  69,  62,  74,  77,  70,\n",
      "         76,  75,   1,   9,  67,  66,  62,  81,  15,   1,  35,  69,  79,  70,\n",
      "         80,   1,  34,  79,  76,  84,  75,  10,   0,  50,  66,  77,  73,  62,\n",
      "         86,   0,  55,  66,   1,  33,  79,  66,   1,  47,  75,  66,   1,   9,\n",
      "         47,  73,  66,   1,  47,  73,  62,  10,   1,  59,  52,  69,  66,   1,\n",
      "         47,  67,  67,  70,  64,  70,  62,  73,   1,  19,  17,  18,  21,   1,\n",
      "         38,  41,  38,  33,   1,  55,  76,  79,  73,  65,   1,  35,  82,  77,\n",
      "          1,  51,  76,  75,  68,  60,   1,   9,  67,  66,  62,  81,  15,   1,\n",
      "         42,  66,  75,  75,  70,  67,  66,  79,   1,  44,  76,  77,  66,  87,\n",
      "          1,   7,   1,  35,  73,  62,  82,  65,  70,  62,   1,  44,  66,  70,\n",
      "         81,  81,  66,  10,   0,   3,  33,  75,  76,  81,  69,  66,  79,   1,\n",
      "         34,  79,  70,  64,  72,   1,  70,  75,   1,  81,  69,  66,   1,  55,\n",
      "         62,  73,  73,  13,   1,  48,  81,  15,   1,  19,   3,   0,  44,  76,\n",
      "         83,  66,   1,  52,  69,  66])\n"
     ]
    }
   ],
   "source": [
    "#Tokenize\n",
    "#Create a mapping of chars to integers \n",
    "stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s] #takes in string, outputs ints\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) #takes in int, outputs string\n",
    "\n",
    "encode(\"Hii there\")\n",
    "print(decode(encode(\"Hii there\")))\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long) \n",
    "\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data \n",
    "\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "#Train on chunks of data aka block size to save computational expense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([81]), the target: 79\n",
      "when input is tensor([81, 79]), the target: 62\n",
      "when input is tensor([81, 79, 62]), the target: 64\n",
      "when input is tensor([81, 79, 62, 64]), the target: 72\n",
      "when input is tensor([81, 79, 62, 64, 72]), the target: 46\n",
      "when input is tensor([81, 79, 62, 64, 72, 46]), the target: 62\n",
      "when input is tensor([81, 79, 62, 64, 72, 46, 62]), the target: 74\n",
      "when input is tensor([81, 79, 62, 64, 72, 46, 62, 74]), the target: 66\n"
     ]
    }
   ],
   "source": [
    "#Training example\n",
    "block_size = 8\n",
    "temp_data = train_data[:block_size+1]\n",
    "x = temp_data[:block_size]\n",
    "y = temp_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context}, the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[70, 82, 74,  1, 50, 66, 74, 70],\n",
      "        [ 0,  3,  3,  3, 34, 47, 48,  3],\n",
      "        [75,  1, 52, 79, 62, 64, 72,  0],\n",
      "        [ 1, 14,  1, 40, 62, 79, 65, 80]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[82, 74,  1, 50, 66, 74, 70, 85],\n",
      "        [ 3,  3,  3, 34, 47, 48,  3,  3],\n",
      "        [ 1, 52, 79, 62, 64, 72,  0, 53],\n",
      "        [14,  1, 40, 62, 79, 65, 80, 81]])\n",
      "------\n",
      "when input is [70], the target is: 82 \n",
      "when input is [70, 82], the target is: 74 \n",
      "when input is [70, 82, 74], the target is: 1 \n",
      "when input is [70, 82, 74, 1], the target is: 50 \n",
      "when input is [70, 82, 74, 1, 50], the target is: 66 \n",
      "when input is [70, 82, 74, 1, 50, 66], the target is: 74 \n",
      "when input is [70, 82, 74, 1, 50, 66, 74], the target is: 70 \n",
      "when input is [70, 82, 74, 1, 50, 66, 74, 70], the target is: 85 \n",
      "when input is [0], the target is: 3 \n",
      "when input is [0, 3], the target is: 3 \n",
      "when input is [0, 3, 3], the target is: 3 \n",
      "when input is [0, 3, 3, 3], the target is: 34 \n",
      "when input is [0, 3, 3, 3, 34], the target is: 47 \n",
      "when input is [0, 3, 3, 3, 34, 47], the target is: 48 \n",
      "when input is [0, 3, 3, 3, 34, 47, 48], the target is: 3 \n",
      "when input is [0, 3, 3, 3, 34, 47, 48, 3], the target is: 3 \n",
      "when input is [75], the target is: 1 \n",
      "when input is [75, 1], the target is: 52 \n",
      "when input is [75, 1, 52], the target is: 79 \n",
      "when input is [75, 1, 52, 79], the target is: 62 \n",
      "when input is [75, 1, 52, 79, 62], the target is: 64 \n",
      "when input is [75, 1, 52, 79, 62, 64], the target is: 72 \n",
      "when input is [75, 1, 52, 79, 62, 64, 72], the target is: 0 \n",
      "when input is [75, 1, 52, 79, 62, 64, 72, 0], the target is: 53 \n",
      "when input is [1], the target is: 14 \n",
      "when input is [1, 14], the target is: 1 \n",
      "when input is [1, 14, 1], the target is: 40 \n",
      "when input is [1, 14, 1, 40], the target is: 62 \n",
      "when input is [1, 14, 1, 40, 62], the target is: 79 \n",
      "when input is [1, 14, 1, 40, 62, 79], the target is: 65 \n",
      "when input is [1, 14, 1, 40, 62, 79, 65], the target is: 80 \n",
      "when input is [1, 14, 1, 40, 62, 79, 65, 80], the target is: 81 \n"
     ]
    }
   ],
   "source": [
    "#Batches\n",
    "torch.manual_seed(1337)\n",
    "batch_size = 4 #how many independent sequences will we process parallel\n",
    "block_size = 8 #Maximum context length for prediction\n",
    "\n",
    "def get_batch(split):\n",
    "    #generate batch of data of inputs and targets\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1: i+block_size+1] for i in ix])\n",
    "    return x, y \n",
    "\n",
    "xb,yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "print('------')\n",
    "\n",
    "for b in range(batch_size): #Batch\n",
    "    for t in range(block_size): #Time\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {context.tolist()}, the target is: {target} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 127])\n",
      "tensor(5.4125, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "ó V\"bj.x58mлSDDIиØÉн“;líRÜdf(>6(NоT]xоeWcn>.CП5Gu®RôD!úAÜJÜj#ö|./!éZÉôн]éZI5_3Ñ-LJ,a2垂d直.OWíоjGFJã3Ó\n"
     ]
    }
   ],
   "source": [
    "from SimpleModel import BigramLanguageModel \n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits,loss = m(xb,yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "#Expected loss = -ln(1/65) ~ 4.17 \n",
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "print(decode(m.generate(idx, max_new_tokens=100)[0].tolist()))\n",
    "#output is total garbage because the model has not been trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start training || Create pyTorch optimizer\n",
    "\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5961947441101074\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "batch_size = 32\n",
    "for steps in range(10000):\n",
    "    #Sample a batch\n",
    "    xb, yb = get_batch('train')\n",
    "    #Evaluate the loss \n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BRe Re>的x\n",
      "GApodsat\n",
      "pemin\n",
      "boncebed\n",
      "Los. N & KODre C od\n",
      "\"B Its Won / VCLAKYown Dr Tr - Faroir Draken)\n",
      "Nayt Ththen Dack (Sleck Cix\n",
      "NEmillo. 4owiteat. Jun\n",
      "Pos Ca)\n",
      "Bony)\n",
      "USteass VELives - Onavig (fek Forx\n",
      "CE\n",
      "E Jidan Onge Les (f h FItl He Anckoreacethou Prs +7 Fom)\n",
      "\"\n",
      "Vinke\n",
      "BONI DOrivls & UPThe Wixy Re Beaish A Tecky Fodinalak Go Thux\n",
      "Rãatep\n",
      "6ix\n",
      "Ratarown Thes) (wn\n",
      "O@>(Dat. Nakix)\n",
      "S\n",
      "Upprtiown)\n",
      "Fown EMy\n",
      "Ze Miarartoul Th Nie\n",
      "Re (ftilalerte & & Rushere Keny Yo\n",
      "Fuck\n",
      "Boanoozeags\n",
      "Ink)\n",
      "Swivif 3Heauis Thictik)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "print(decode(m.generate(idx, max_new_tokens=500)[0].tolist()))\n",
    "\n",
    "#Simple model, tokens do not communicate with each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The mathmatical trick in self attention \n",
    "\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape\n",
    "#Tokens need to be able to communicate with all previous tokens, but None of the future ones as thats what we are predicting\n",
    "\n",
    "#We want x[b,t] = mean {i<=t} x[b,i]\n",
    "#Version 1\n",
    "xbow = torch.zeros((B,T,C)) \n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1]\n",
    "        xbow[b,t]= torch.mean(xprev,0)\n",
    "#Version 2\n",
    "#created weighted sums\n",
    "wei = torch.ones(T,T)\n",
    "wei = torch.tril(wei)\n",
    "#now all rows sum to one\n",
    "wei = wei / wei.sum(1,keepdim=True)\n",
    "xbow2 = wei @ x #(B,T,T) @ (B,T,C) --> (B,T,C)\n",
    "#xbow = xbow2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "---\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "---\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "#Matrix multiply as weighted aggregation\n",
    "\n",
    "torch.manual_seed(42)\n",
    "a = torch.ones(3,3)\n",
    "a = torch.tril(a)\n",
    "#now all rows sum to one\n",
    "a = a / torch.sum(a,1,keepdim=True)\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b \n",
    "\n",
    "print('a=')\n",
    "print(a)\n",
    "print('---')\n",
    "print('b=')\n",
    "print(b)\n",
    "print('---')\n",
    "print('c=')\n",
    "print(c)\n",
    "print('---')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sck Apstoots Ad Boconex\n",
      "Noown\n",
      "Gougopser\n",
      "Whby Sh (fffe I’t Anno APt Felte Ch Hem Tomy - (fethaix\n",
      "HI LyTh rt. PHHeietheletybyd\n",
      "BA (ffearalit. & T (wk AG Areagalke & tothemipievin Aners\n",
      "Ch Yed\n",
      "Ustimedmips - Dourt (IFe (Fured\n",
      "VEDr)\n",
      "\"\n",
      "MXXIt. Reavera Yongion Bingem)\n",
      "Kn) - Mensthrts B Mamsn\n",
      "Baimabernat.Op\n",
      "I TAn hthe F)\n",
      "HTunkel\n",
      "B. Nodón\n",
      "Sweeare Bay (Bor Lix\n",
      "Cht THatr a® Jigshew Jimee (ffeampake m. (fr)\n",
      "Art (femá\n",
      "UCollbape Me Ous SDraty Carat Liatas iloup\n",
      "7 (feat Turerb NTr. Nix\n",
      "Un fe Drrnosh Gund Emive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tes = torch.load('/Users/iansnyder/Desktop/Projects/Spotify_Proj/src/model/BigramLanguageModel.pth')\n",
    "\n",
    "from bigram_train import BigramLanguageModel \n",
    "\n",
    "m = BigramLanguageModel(vocab_size=vocab_size)\n",
    "m.load_state_dict(tes['model_state_dict'])\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-2)\n",
    "optimizer.load_state_dict(tes['optimizer_state_dict'])\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
